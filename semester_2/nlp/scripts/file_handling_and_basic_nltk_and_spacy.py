# -*- coding: utf-8 -*-
"""File Handling and Basic NLTK and Spacy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xObtlL4CaZ85i22SAk2SrnGwNsp4sLZw
"""

#1. Read a text file.
#2. Find out the number of (a) words, (b) lines, etc.
#3. Basic NLTK

f = open("Hamlet.txt", "r")
data = f.read()

words = data.split(" ")
lines = data.split("\n")
fields = data.split("\t")
print(len(words))
print(len(lines))
print(len(fields))

str = "The rain in Spain stays mainly in the plain."

#Use NLTK for the following tasks

import nltk
#nltk.download('punkt_tab')
#1. Tokenize a text into number of words
#2. Tokenize a text into number of sentences
from nltk.tokenize import sent_tokenize, word_tokenize

sentenceTokens = sent_tokenize(str)
wordTokens = word_tokenize(str)
print("Sentence Tokenization:", sentenceTokens)
print("Word Tokenization:", wordTokens)

#1. Reading a text file.
#2. Some basic string operations
#3. Tokenization using NLTK.
#4. Part-of-Speech Tagging Using NLTK.

str = "Long years ago we made a tryst with destiny, and now the time comes when we shall redeem our pledge. Not wholly or in full measure, but quite substantially. At the stroke of the midnight hour, when the world sleeps, India will awake to life and freedom."
from nltk import pos_tag
#nltk.download('averaged_perceptron_tagger_eng')
print("Number of sentences:", len(sent_tokenize(str)))
print("Number of words:", len(word_tokenize(str)))
taggedTokens = pos_tag(word_tokenize(str))
#print(taggedTokens)
for taggedToken in taggedTokens:
  (token, tag) = taggedToken
  print(token + "_" + tag)
  #print(tag)
print(len(taggedTokens))

i = 0
for sentence in sent_tokenize(str):
  taggedTokens = pos_tag(word_tokenize(sentence))
  print(taggedTokens)
  i += len(taggedTokens)
print(i)

import spacy
#1. Some NLP tasks like PoS tagging, tokenization, etc. in Spacy.
str = "Mr. Smith goes to Washington"
nlp = spacy.blank("en")
doc = nlp(str)
for token in doc:
  print(token)

nlp = spacy.load("en_core_web_sm")
doc = nlp("Long years ago we made a tryst with destiny, and now the time comes when we shall redeem our pledge. Not wholly or in full measure, but quite substantially. At the stroke of the midnight hour, when the world sleeps, India will awake to life and freedom.")

print("Text\tlemma\tpos\ttag\tdep\tshape_")
for token in doc:
  print(token.text + "\t" + token.lemma_ + "\t" + token.pos_ + "\t" + token.tag_ + "\t" + token.dep_ + "\t" + token.shape_)

outputFile = "output.txt"
f = open("output.txt", "a")
outputStr = "Text\tlemma\tpos\ttag\tdep\tshape_\n"
f.write(outputStr)
for token in doc:
  outputStr = token.text + "\t" + token.lemma_ + "\t" + token.pos_ + "\t" + token.tag_ + "\t" + token.dep_ + "\t" + "\n"
  f.write(outputStr)

f.close()

f = open("output.txt", "r")
savedData = f.read()
f.close()

print(len(savedData.split("\n")))